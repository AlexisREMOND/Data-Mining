---
title: "Data_mining"
author: "Alexis REMOND"
date: "19/01/2022"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    math: katex
---

Nous installons d'abord tous les packages dont l'on aura besoin lors de notre analyse de la base de données.

```{r,warning=FALSE}
.libPaths("D:/2ème année/s3/R/Packages R")
library(tidyverse)
library(car)
library(tibble)
library(forcats)
library(ggplot2)
library(readr)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(ggeffects)
library(effects)

```

Lors de notre Tp de Data mining, nous devions analyser les difficultés financières des exploitations agricoles. 
Nous disposons d’un jeu de données constitué de 1 260 exploitations issues des départements de l’Eure-27 (348
exploitations), du Nord-59 (282 exploitations), de l’Orne-61 (333 exploitations), et de la Seine-Maritime-76
(297 exploitations) comparables dans leurs productions agricoles dominantes car spécialisées pour la plupart
dans les grandes cultures. Les sous-échantillons sont équilibrés dans leur effectif et l’observation réalisée
couvre la période 1988 à 1994. On dispose notamment de la variable indicateur de difficulté financière.
On dispose aussi d’une batterie de critères économiques et financiers comprenant 22 ratios sélectionnés selon
les thématiques suivantes :
  • Capitalisation
    – r1 dette totale / actif total ;
    – r2 capitaux propres / capital investi ;
    – r3 dette à court terme / dette totale ;
    – r4 dette à court terme/total de l’actif ;
    – r5 dette à long et moyen terme / total de l’actif ;
  • Poids de la dette
    – r6 dette totale / produit brut ;
    – r7 dette long et moyen terme / produit brut ;
    – r8 dette à court terme / produit brut ;
  • Liquidité
    – r11 fonds de roulement / produit brut ;
    – r12 fonds de roulement / (intrants réels - frais financiers) ;
    – r14 dette à court terme / actifs circulants ;
  • Service de la dette
    – r17 frais financiers / dette totale ;
    – r18 frais financiers / produit brut ;
    – r19 (frais financiers + remboursement du capital long et moyen terme) / produit brut ;
    – r21 charges financières / EBITDA ;
    – r22 (charges financières + remboursement du capital long et moyen terme)/EBITDA ;
  • Rentabilité du capital
    – r24 EBITDA /total de l’actif ;
  • Bénéfice
    – r28 EBITDA / produit brut ;
    – r30 revenu disponible / produit brut ;
    – r32 (EBITDA - frais financiers) / produit brut ;
  • Activité productive
    – r36 actifs immobilisés / produit brut ;
    – r37 produit brut / actif total.

Non avons pour objectif d'analyser les causes de difficulté financière des exploitations agricoles, de trouver un modèle permettant d’identifier les exploitations agricoles en difficulté financière afin de les
prévenir. Puis faire un rapport écrit et oral de nos résultats.

On importe la base de données, qui nous a été donné par Madame GEY, notre professeur de Data Mining, au format csv

```{r, message=FALSE, echo=FALSE}
donnee<-read.csv("D:/2ème année/s4/Data mining/Desbois_data_origine.csv", sep = ";")
```


```{r,warning=FALSE}
#donnee$DIFF<-factor(donnee$DIFF,labels=c("Pas difficultés", "Difficultés"))

#colnames(donnee)<-c("Incident de payement","dette totale / actif total","capitaux propres / capital investi", "dette #à court terme / dette totale","dette à court terme/total de l’actif ","dette à long et moyen terme / total de #l’actif ", "dette totale / produit brut","dette long et moyen terme / produit brut ", "dette à court terme / produit #brut", "fonds de roulement / produit brut","fonds de roulement / (intrants réels - frais financiers) ","dette à #court terme / actifs circulants ","frais financiers / dette totale", "frais financiers / produit brut","(frais #financiers + remboursement du capital long et moyen terme) / produit brut ","charges financières / EBITDA","(charges #financières + remboursement du capital long et moyen terme)/EBITDA","EBITDA /total de l’actif"," EBITDA / produit #brut"," revenu disponible / produit brut","(EBITDA - frais financiers) / produit brut ", " actifs immobilisés / #produit brut ","produit brut / actif total")
```
On met ces instructions entre parenthèses car elles permettent de changer le nom des variables. Dans notre base de données, les noms des variables sont trop longs, il est préférable de laisser comme tel.

On regarde avec la fonction is.na() le nombre de valeur manquante.
```{r,warning=FALSE}
sum(is.na(donnee))
```

On voit qu'il y a 0 valeur manquante dans la base de données

On peut regarder à quoi ressemble notre jeu de données, avec le minimum, le premier quartile, la mediane, la moyenne, le troisième quartile et le maximum.
```{r}
summary(donnee)
knitr::kable(head(donnee))
```


## 2.1 Statistique univariée

Nous allons commencer notre étude par une analyse univariée
### 2.1.1 Variables qualitatives

On démarre par la variable qualitative, il n'y en a qu'une seule et c'est la variable DIFF
```{r,warning=FALSE}
p1 = prop.table(table(donnee$DIFF))
pie(p1, col = c("blue","red"))
```

On peut voir sur ce diagramme circulaire qu'il y a plus d'exploitation qui non pas de difficulté financière. 

### 2.1.2 Variables quantitatives
On continue par les variables quantitatives, qui constituent le reste de notre base de données
```{r,warning=FALSE}
donnees_quanti=donnee[,-1]
donnees_quanti_cr=scale(donnees_quanti)

boxplot(donnees_quanti_cr)


sequence=2:23
par(mfrow = c(2,4))
for(i in sequence){
  hist(donnee[ , i], 
       prob = TRUE,
       main = colnames(donnee)[i])
}
```



## 2.2 Statistique bivariée
### 2.2.1 Variables quantitatives et qualitative

On décide aussi de faire une analyse bivariée de la variable DIFF par rapport aux autres variables. Les diagrammes représentés sont des boîtes à moustaches
```{r,warning=FALSE}
sequence=2:23
par(mfrow = c(1,3))
for(i in sequence){
  boxplot(donnee[ , i]~donnee$DIFF,
       main = c(colnames(donnee)[i],"selon le paiement"),col="cornflowerblue")
}
```

Nous avois fait un test de student pour chaque variables. Afin de voir la différence entre les moyennes. 
```{r,warning=FALSE}

t.test(donnee$R1~donnee$DIFF)
t.test(donnee$R2~donnee$DIFF)
t.test(donnee$R3~donnee$DIFF)
t.test(donnee$R4~donnee$DIFF)
t.test(donnee$R5~donnee$DIFF)
t.test(donnee$R6~donnee$DIFF)
t.test(donnee$R7~donnee$DIFF)
t.test(donnee$R8~donnee$DIFF)
t.test(donnee$R11~donnee$DIFF)
t.test(donnee$R12~donnee$DIFF)
t.test(donnee$R14~donnee$DIFF)
t.test(donnee$R17~donnee$DIFF)
t.test(donnee$R18~donnee$DIFF)
t.test(donnee$R19~donnee$DIFF)
t.test(donnee$R21~donnee$DIFF)
t.test(donnee$R22~donnee$DIFF)
t.test(donnee$R24~donnee$DIFF)
t.test(donnee$R28~donnee$DIFF)
t.test(donnee$R30~donnee$DIFF)
t.test(donnee$R32~donnee$DIFF)
t.test(donnee$R36~donnee$DIFF)
t.test(donnee$R37~donnee$DIFF)

```



## 3. Analyse en Composante Principal

On cherche à savoir qu'elles sont les variables qui représentent le mieux la variable DIFF, on va réaliser une ACP (Analyse de Composantes Principales)
```{r,warning=FALSE}

library(FactoMineR)
donnees.acp=PCA(donnee,ncp=23,graph=TRUE)

```

# Choix du nombre de facteurs

Nous avons appris en cours que la règle de Kaiser et l'éboulie des valeurs propres peuvent nous aider à choisir le nombre de facteurs. La règle de Kaiser permet de garder les axes qui correspondent aux valeurs propres supérieures à 1. L'ébouli des valeurs propres sert à garder les axes qui correspondent aux valeurs propres situées avant le point d'inflexion. 
```{r,warning=FALSE}

library(factoextra)
vp=donnees.acp$eig %>% data.frame %>% rownames_to_column(var="Composante") %>% as_tibble

fviz_eig(donnees.acp,choice="eigenvalue") +
  geom_hline(yintercept = 1,col="red")

```

Nous pouvons voir sur le premier graphe que les points d'inflexion sont sur le point 6, il y a donc 5 axes qui ont une valeur propre supérieur à 1. 

# Pourcentage de variance expliquée cumulée

On utilise le pourcentage de variance expliqué cumulée, autrement appelé règle empirique, pour garder les facteurs qui sont supérieurs à un certain pourcentage. Ici, on prendra 80%.
Pour cette méthode, on gardera les facteurs ayant un pourcentage de variance cumulée inférieure ou égale à notre seuil de 80%, jusqu'à avoir dépassé ce seuil.
```{r,warning=FALSE}
ggplot(vp) + geom_col(aes(x=Composante, y = cumulative.percentage.of.variance)) +
  ggtitle("Pourcentage de variance expliquée cumulée") + geom_hline(aes(yintercept=80),color='red')

```

On peux voir sur ce graphqiue que les 4 premiers facteurs expliquent 80% de la variance cumulée. 

# Pourcentage de variance expliquée

Ici, on utilise un seuil de 10% 
```{r,warning=FALSE}
ggplot(vp) + geom_col(aes(x=Composante, y = percentage.of.variance)) +
  ggtitle("Pourcentage de variance expliquée") + geom_hline(aes(yintercept=10),color='red')
```

On peux voir sur ce graphiques que les 4 premières composantes ont un pourcentage de variance expliqué supérieur à 10%

#Description des axes retenus

```{r,warning=FALSE}
fviz_contrib(donnees.acp,choice="var",axes=1)
fviz_contrib(donnees.acp,choice="var",axes=2)
fviz_contrib(donnees.acp,choice="var",axes=3)

```

Sur ces trois graphiques, on remarque que les variables qui contribuent le plus sont :

  - L'axe 1 : R30, R6, R18, R8, R21, R32, R1, R19, R2, R22, R14, R4, R11 et R12
  - L'axe 2 : R37, R36, R3, R4, R24, R7, R11, R12 et R14
  - L'axe 3 : R5, R3, R24, R28, R2, R1, R7 et R32
  

# Qualité de représentation 
```{r,warning=FALSE}
fviz_cos2(donnees.acp,choice="var",axes=1) +
  geom_hline(yintercept = 0.6,col="red")
fviz_cos2(donnees.acp,choice="var",axes=2)+
  geom_hline(yintercept = 0.6,col="red")
fviz_cos2(donnees.acp,choice="var",axes=3)+
  geom_hline(yintercept = 0.6,col="red")
```

Sur ce graphique avec les cosinus², on remarque que les variables qui contribuent le plus sont :

  - L'axe 1 : R30, R6, R18, R8, R21, R32, R1 et R19
  - L'axe 2 : R37
  - L'axe 3 : aucune variable
  

# Les cercles de corrélation

Grâce à ces cercles de corrélation, nous pourrons voir les différentes variables corrélées
```{r,warning=FALSE}
plot(donnees.acp,choix="var",axes=1:2)
plot(donnees.acp,choix="var",axes=2:3)
plot(donnees.acp,choix="var",axes=c(1,3))
```

On peut voir que sur l'axe 1, du côté droit du cercle, sont les variables qui contribuent positivement sur la dimension 1, il y a R4, R1, R8, R21 et R18. Et du côté gauche du cercle, ce sont les variables qui contribuent négativement sur la dimension 1. il y a R30, R32 et R2.
Sur l'axe 2, les variables qui contribuent positivement sont R37 et R24. Alors que ce sont les variables R36 et R2 qui contribuent négativement sur la dimension 2.
Sur l'axe 3, les variables qui contribuent positivement sont R1, R6, R18, R14, R21 et R8. Alors que ce sont les variables R30, R32 et R2 qui contribuent négativement sur la dimension 3.

#Interprétation

```{r,warning=FALSE}
#plotellipses(donnees.acp)
#plotellipses(donnees.acp,axes=c(1,3))
```

#Corrélation

#Matrice de corrélation 

```{r,warning=FALSE}
mcor = cor(donnee)
mcor
```

On peut voir sur la table les coefficients de corrrélation sont montrés entre les différentes paires possibles de variables.

```{r}
col<- colorRampPalette(c("blue", "white", "red"))(20)
heatmap(x = mcor, col = col, symm = TRUE)
```

X est la matrice de corrélation
symm est la valeur logique si x devrait être traité comme symétrique; peut être true si seulement si x est une matrice carrée.

#Table de corrélation
```{r,warning=FALSE}
df=as.data.frame(as.table(cor(donnee)))
dff=df[1:23,]
```

On crée un tableau afin de voir mieux en détails nos résultat.


```{r,warning=FALSE}
symnum(mcor,abbr.colnames=FALSE)
```
Comme on peut le voir dans la légende, les coefficients de corrélation entre 0 et 0.3 sont remplacés par un espace (""); les coefficients de corrélation entre 0.3 et 0.6 sont remplacés par "."; les coefficients de 0.8 sont remplacé par (+) et de 0.9 par (*)

#Corrélation en format graphique 
```{r,warning=FALSE}
library(corrplot)
corrplot(mcor, method="circle") #Version avec cercle
```

Grâce à cette matrice, representé sous differents forme,on remarque que la variable DIFF est fortement corrélé positivement avec la variable R1, R7, R22, R32

#Modele logistique 

L’objectif est de trouver les variables explicatives significatives et le meilleur seuil associé.

```{r,warning=FALSE}
model = glm(DIFF~.,data = donnee, family = binomial(logit))
names(model)

summary(model)

```


```{r,warning=FALSE}
exp(cbind(coef(model), confint(model)))
```

Avec cette fonction, on peut voir les coefficients du modèle et leurs intervalles de confiance.

#Apprentissage vs Test

Nous allons echantilloner notre base pour avoir un échantillon d'apprentissage. On fait un tirage aléatoire et sans remise pour que 80% (seuil de base) des données constitue l'échantillon d'apprentissage. Et 20% l'échantillon de test.
```{r}
set.seed(200)
id_appren = sort(sample(nrow(donnee), floor(nrow(donnee) * 0.80)))

donnee_appren <- donnee[id_appren, ] #donnée apprentissage

donnees_test <- donnee[-id_appren, ]# Echantillon de test


summary(donnee_appren)

str(donnee_appren)
```

```{r, warning=FALSE}
model_appren=glm(DIFF~., data = donnee_appren, family = binomial)
summary(model_appren)
```


#Selection de variables

On cherche à trouver un sous ensemble de variables suffisantes pour expliquer les difficultés financières des exploitations agricoles.
```{r, warning=FALSE}
model_AIC=step(model_appren,direction="both",trace=TRUE)
summary(model_AIC)

```

On voit que notre code nous donne R1 + R3 + R8 + R14 + R17 + R22 + R28 + R30 + R36 + R37 comme variables suffisantes à expliquer les difficultés financières des exploitations agricoles.

#Interprétation 
```{r,warning=FALSE}
#oddss ratio
library(GGally)

ggcoef(model_AIC, exponentiate = TRUE, color = "blue", size = 5, shape = 18) 
ggcoef_model(model_AIC, exponentiate = TRUE)

exp(coef(model_AIC))
exp(confint(model_AIC))
```

Dans le premier graphique, plus les losanges sont écartés de 1, plus les variables sont importantes.
Dans le deuxième graphique, nous avons les mêmes résultats que les graphique précedents, avec les p-valeurs en plus à côté

```{r,warning=FALSE}
#library(ggeffects)
#library(effects)
#ggeffect(model_AIC)
#plot(ggeffect(model_AIC))
#forest_model(model_AIC)
#cowplot::plot_grid(plotlist = plot(ggeffect(model_AIC)))

```

Sur ces graphique, on voit l'évolution des variables en fonction de la variable DIFF.


```{r,warning=FALSE}
#library(effects)
#plot(allEffects(model_AIC))
```

Voici les courbes récapitulatifs des évolutions des variables.


#Echantillon test 

```{r}
ystar = predict(model_AIC, newdata = donnees_test)

muhat= predict(model_AIC, newdata = donnees_test, type="response")

muhat

yhat = factor(as.numeric(muhat > 0.5))
yhat

mat.conf <- addmargins(table(Predicted=yhat,Actual=donnees_test$DIFF))
mat.conf

mat.conf[1, 1:2]/mat.conf[3, 1:2]
(mat.conf[1, 1] + mat.conf[2, 2])/sum(mat.conf[3, 1:2])
c(mat.conf[1, 1]/mat.conf[3, 1],mat.conf[2, 2]/mat.conf[3, 2])

pred = data.frame(Actual = donnees_test$DIFF, Predicted = yhat)
cible = pred %>% filter(Actual == 1)
100*sum(cible$Actual != cible$Predicted)/nrow(cible)
```

On peut remarquer dans cette sortie R la matrice de confusion, le taux de vrai positif (0.9375000) et le taux de faux positif (0.1290323). La précision de ce test est de 0.9047619, que sa sensitivité est de 0.9375000 et que sa spécificité est de 0.8709677. Son taux de mauvais classement est de 12.90323. 

#Courbes ROC et calcul l'AUC
```{r,warning=FALSE}
#library(ROCR)
#pred_test <- prediction(muhat, donnee_test$DIFF)
#perf_test <- performance(pred_test, measure = "tpr", x.measure = "fpr")
#plot(perf_test, colorize = T, print.cutoffs.at = seq(0, 1,by = 0.1), text.adj = c(1.2, 1.2), lwd = 3)
```

#Calcul l'AUC
```{r,warning=FALSE}
#perf_test_auc= performance(pred_test, "auc")
#perf_test_auc@y.values[[1]]
```


#Validation croisée

La validation croisée va nous permettre d’utiliser l’intégralité de notre base de données pour l’entraînement et pour la validation.
On va donc diviser les données en K groupes et pour chaque groupe, créer un modèle glm.
```{r,warning=FALSE}
library(boot)
res.glm <- glm(model_AIC$formula , family = binomial(link = "logit"),data = donnee)
cout <- function(r, pi = 0) mean(abs(r - pi) > 0.5)
res.cv <- cv.glm(donnee, res.glm,cout, K = 10)

res.cv$delta[1]
```

On trouve 0.1095238 comme eurreur moyenne sur le K=10 validations croisées.


#Conclusion

Pour conclure, grâce à nos test et à nos sorties R, on remarque que les ratios mettant en difficulté financières les exploitations financières sont les "dette totale / actif total" autrement dit R1, les "dette à court terme / dette totale" autrement dit R3, les "dette à court terme / produit brut " autrement dit R8, les "fonds de roulement / (intrants réels - frais financiers)" autrement dit R12, les "dette à court terme / actifs circulants" autrement dit R14, les "frais financiers / dette totale" autrement dit R17, les "(charges financières + remboursement du capital long et moyen terme)/EBITDA " autrement dit R22, les "EBITDA / produit brut" autrement dit R28, les "revenu disponible / produit brut" autrement dit R30, les "actifs immobilisés / produit brut"  autrement dit R36 et les "produit brut / actif total" autrement dit R37. L'exploitant agricole devra donc faire attention à ces ratios afin d'éviter de tomber dans la difficulté financières. Nous pourrions nous demander si nous retrouvons ces mêmes difficultés dans un autre domaine d'activité.


